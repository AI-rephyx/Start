{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtLcGau2aZZVzX+9Mafcet",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-rephyx/Start/blob/master/Project/python_data_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. load_digits : 손글씨 분류**"
      ],
      "metadata": {
        "id": "5Msbme6rxLLI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hij4tHiBwHHu",
        "outputId": "4b3a8e96-42bd-40cf-a132-923e6a176bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.2\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "jS9Ycy9LwSjR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드\n",
        "digits = load_digits()\n",
        "\n",
        "# 데이터 확인\n",
        "print(f\"데이터 형태: {digits.data.shape}\")\n",
        "print(f\"라벨 형태: {digits.target.shape}\")\n",
        "\n",
        "# 데이터의 첫 번째 샘플과 해당 라벨 확인\n",
        "print(f\"첫 번째 샘플 데이터: {digits.data[0]}\")\n",
        "print(f\"첫 번째 샘플 라벨: {digits.target[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dWj-VC7wZDu",
        "outputId": "5fdd35d6-1776-4053-ac71-75436e590b34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 형태: (1797, 64)\n",
            "라벨 형태: (1797,)\n",
            "첫 번째 샘플 데이터: [ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
            " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
            "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
            "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
            "첫 번째 샘플 라벨: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Data\n",
        "feature_data = digits.data\n",
        "print(f\"Feature Data Shape: {feature_data.shape}\")\n",
        "\n",
        "# Label Data\n",
        "label_data = digits.target\n",
        "print(f\"Label Data Shape: {label_data.shape}\")\n",
        "\n",
        "# Target Names\n",
        "print(f\"Target Names: {digits.target_names}\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Feature Data를 DataFrame으로 변환\n",
        "feature_df = pd.DataFrame(feature_data)\n",
        "\n",
        "# DataFrame 요약 정보 출력\n",
        "print(feature_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlmv4pz7w0jp",
        "outputId": "714e601c-16a5-44d0-a72d-3a17c5c65d1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Data Shape: (1797, 64)\n",
            "Label Data Shape: (1797,)\n",
            "Target Names: [0 1 2 3 4 5 6 7 8 9]\n",
            "           0            1            2            3            4   \\\n",
            "count  1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
            "mean      0.0     0.303840     5.204786    11.835838    11.848080   \n",
            "std       0.0     0.907192     4.754826     4.248842     4.287388   \n",
            "min       0.0     0.000000     0.000000     0.000000     0.000000   \n",
            "25%       0.0     0.000000     1.000000    10.000000    10.000000   \n",
            "50%       0.0     0.000000     4.000000    13.000000    13.000000   \n",
            "75%       0.0     0.000000     9.000000    15.000000    15.000000   \n",
            "max       0.0     8.000000    16.000000    16.000000    16.000000   \n",
            "\n",
            "                5            6            7            8            9   ...  \\\n",
            "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
            "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
            "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
            "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
            "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
            "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
            "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
            "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
            "\n",
            "                54           55           56           57           58  \\\n",
            "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
            "mean      3.725097     0.206455     0.000556     0.279354     5.557596   \n",
            "std       4.919406     0.984401     0.023590     0.934302     5.103019   \n",
            "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
            "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
            "50%       1.000000     0.000000     0.000000     0.000000     4.000000   \n",
            "75%       7.000000     0.000000     0.000000     0.000000    10.000000   \n",
            "max      16.000000    13.000000     1.000000     9.000000    16.000000   \n",
            "\n",
            "                59           60           61           62           63  \n",
            "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
            "mean     12.089037    11.809126     6.764051     2.067891     0.364496  \n",
            "std       4.374694     4.933947     5.900623     4.090548     1.860122  \n",
            "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
            "25%      11.000000    10.000000     0.000000     0.000000     0.000000  \n",
            "50%      13.000000    14.000000     6.000000     0.000000     0.000000  \n",
            "75%      16.000000    16.000000    12.000000     2.000000     0.000000  \n",
            "max      16.000000    16.000000    16.000000    16.000000    16.000000  \n",
            "\n",
            "[8 rows x 64 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터를 train과 test로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    feature_data,    # Feature Data\n",
        "    label_data,      # Label Data\n",
        "    test_size=0.2,   # Test 데이터 비율 (20%)\n",
        "    random_state=42  # Random Seed 값\n",
        ")\n",
        "\n",
        "# 분리된 데이터의 크기 확인\n",
        "print(f\"X_train Shape: {X_train.shape}\")\n",
        "print(f\"X_test Shape: {X_test.shape}\")\n",
        "print(f\"y_train Shape: {y_train.shape}\")\n",
        "print(f\"y_test Shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeF6lgCGxSdB",
        "outputId": "3256334a-de21-426a-9d39-0cca8c20d131"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Shape: (1437, 64)\n",
            "X_test Shape: (360, 64)\n",
            "y_train Shape: (1437,)\n",
            "y_test Shape: (360,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 각 모델 초기화\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC(),\n",
        "    \"SGD Classifier\": SGDClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "# 모델 학습 및 테스트\n",
        "for model_name, model in models.items():\n",
        "    print(f\"### {model_name} ###\")\n",
        "    # 학습\n",
        "    model.fit(X_train, y_train)\n",
        "    # 예측\n",
        "    y_pred = model.predict(X_test)\n",
        "    # 성능 평가\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUgiJQNuxfAY",
        "outputId": "85843dbd-5d56-4c20-dca3-4713ce7001f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Decision Tree ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.88      0.92        33\n",
            "           1       0.85      0.79      0.81        28\n",
            "           2       0.86      0.73      0.79        33\n",
            "           3       0.76      0.85      0.81        34\n",
            "           4       0.84      0.91      0.88        46\n",
            "           5       0.89      0.85      0.87        47\n",
            "           6       0.97      0.91      0.94        35\n",
            "           7       0.82      0.91      0.86        34\n",
            "           8       0.75      0.70      0.72        30\n",
            "           9       0.75      0.82      0.79        40\n",
            "\n",
            "    accuracy                           0.84       360\n",
            "   macro avg       0.84      0.84      0.84       360\n",
            "weighted avg       0.85      0.84      0.84       360\n",
            "\n",
            "\n",
            "\n",
            "### Random Forest ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        33\n",
            "           1       0.97      1.00      0.98        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       1.00      0.94      0.97        34\n",
            "           4       0.98      1.00      0.99        46\n",
            "           5       0.94      0.96      0.95        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       0.97      0.97      0.97        34\n",
            "           8       0.97      0.97      0.97        30\n",
            "           9       0.95      0.95      0.95        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n",
            "\n",
            "\n",
            "### SVM ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       1.00      1.00      1.00        46\n",
            "           5       0.98      0.98      0.98        47\n",
            "           6       0.97      1.00      0.99        35\n",
            "           7       0.97      0.97      0.97        34\n",
            "           8       1.00      0.97      0.98        30\n",
            "           9       0.95      0.95      0.95        40\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "\n",
            "\n",
            "### SGD Classifier ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       0.90      0.96      0.93        28\n",
            "           2       0.97      1.00      0.99        33\n",
            "           3       1.00      0.94      0.97        34\n",
            "           4       1.00      0.98      0.99        46\n",
            "           5       0.90      0.94      0.92        47\n",
            "           6       1.00      0.94      0.97        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       0.75      0.90      0.82        30\n",
            "           9       0.97      0.85      0.91        40\n",
            "\n",
            "    accuracy                           0.95       360\n",
            "   macro avg       0.95      0.95      0.95       360\n",
            "weighted avg       0.95      0.95      0.95       360\n",
            "\n",
            "\n",
            "\n",
            "### Logistic Regression ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       0.97      1.00      0.98        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       0.97      0.97      0.97        34\n",
            "           4       1.00      0.98      0.99        46\n",
            "           5       0.92      0.96      0.94        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       0.97      0.97      0.97        30\n",
            "           9       0.97      0.95      0.96        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.98      0.97      0.98       360\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##sklearn의 classification_report\n",
        "##4개의 지표를 모두 포함하고 있어 모델 성능을 종합적으로 평가하는 데 유용\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "random_forest = models[\"Random Forest\"]\n",
        "\n",
        "# 예측 결과\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "# 성능 평가\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJWCWQtmxvvx",
        "outputId": "1c3a1822-9be9-49f9-ba80-d97ce5bce338"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        33\n",
            "           1       0.97      1.00      0.98        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       1.00      0.94      0.97        34\n",
            "           4       0.98      1.00      0.99        46\n",
            "           5       0.94      0.96      0.95        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       0.97      0.97      0.97        34\n",
            "           8       0.97      0.97      0.97        30\n",
            "           9       0.95      0.95      0.95        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. load_wine : 와인 분류**"
      ],
      "metadata": {
        "id": "MfySqKkIyl_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "zuKPymUXysPH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "wine = load_wine()\n",
        "\n",
        "# 데이터 이해를 돕기 위해 키 확인\n",
        "print(wine.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKt-prTWyxNj",
        "outputId": "7bf3b360-e88b-4d7b-8c16-720aba67fe51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Data\n",
        "wine_data = wine.data  # wine 데이터의 feature 부분\n",
        "print(\"Feature Data Shape:\", wine_data.shape)  # 데이터 크기 확인 (샘플 수, 특성 수)\n",
        "\n",
        "# Label Data\n",
        "wine_label = wine.target  # wine 데이터의 target 부분\n",
        "print(\"Label Data Shape:\", wine_label.shape)  # 라벨 크기 확인\n",
        "print(\"Label Data Sample:\", wine_label[:10])  # 라벨 데이터 일부 확인\n",
        "\n",
        "# Target Names\n",
        "print(\"Target Names:\", wine.target_names)  # 각 라벨에 대한 타겟 이름\n",
        "\n",
        "# Data Describe\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터를 DataFrame으로 변환\n",
        "wine_df = pd.DataFrame(wine_data, columns=wine.feature_names)\n",
        "\n",
        "# 데이터 기술 통계 출력\n",
        "print(\"\\nFeature Description:\\n\", wine_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3UlkQ0JzGTy",
        "outputId": "86ec1d46-1588-4c23-e4fc-758aef27c130"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Data Shape: (178, 13)\n",
            "Label Data Shape: (178,)\n",
            "Label Data Sample: [0 0 0 0 0 0 0 0 0 0]\n",
            "Target Names: ['class_0' 'class_1' 'class_2']\n",
            "\n",
            "Feature Description:\n",
            "           alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
            "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
            "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
            "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
            "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
            "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
            "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
            "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
            "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
            "\n",
            "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
            "count     178.000000  178.000000            178.000000       178.000000   \n",
            "mean        2.295112    2.029270              0.361854         1.590899   \n",
            "std         0.625851    0.998859              0.124453         0.572359   \n",
            "min         0.980000    0.340000              0.130000         0.410000   \n",
            "25%         1.742500    1.205000              0.270000         1.250000   \n",
            "50%         2.355000    2.135000              0.340000         1.555000   \n",
            "75%         2.800000    2.875000              0.437500         1.950000   \n",
            "max         3.880000    5.080000              0.660000         3.580000   \n",
            "\n",
            "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
            "count       178.000000  178.000000                    178.000000   178.000000  \n",
            "mean          5.058090    0.957449                      2.611685   746.893258  \n",
            "std           2.318286    0.228572                      0.709990   314.907474  \n",
            "min           1.280000    0.480000                      1.270000   278.000000  \n",
            "25%           3.220000    0.782500                      1.937500   500.500000  \n",
            "50%           4.690000    0.965000                      2.780000   673.500000  \n",
            "75%           6.200000    1.120000                      3.170000   985.000000  \n",
            "max          13.000000    1.710000                      4.000000  1680.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Feature Data와 Label Data 설정\n",
        "X = wine.data  # Feature Data\n",
        "y = wine.target  # Label Data\n",
        "\n",
        "# Train-Test Split (80% 학습 데이터, 20% 테스트 데이터)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 분리된 데이터 크기 확인\n",
        "print(\"X_train Shape:\", X_train.shape)\n",
        "print(\"X_test Shape:\", X_test.shape)\n",
        "print(\"y_train Shape:\", y_train.shape)\n",
        "print(\"y_test Shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrasDuqOzlWP",
        "outputId": "2eeff291-9246-4018-a566-ac773ac16bd7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Shape: (142, 13)\n",
            "X_test Shape: (36, 13)\n",
            "y_train Shape: (142,)\n",
            "y_test Shape: (36,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 모델 리스트\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "    \"SGD Classifier\": SGDClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "}\n",
        "\n",
        "# 모델 학습 및 평가\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    # 모델 학습\n",
        "    model.fit(X_train, y_train)\n",
        "    # 테스트 데이터 예측\n",
        "    y_pred = model.predict(X_test)\n",
        "    # 성능 평가\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhmFCuDSz3Zs",
        "outputId": "ca9c47d8-4fcb-4cd3-b918-bbed387a5642"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Decision Tree ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        14\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.95      0.93      0.94        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "\n",
            "=== Random Forest ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "\n",
            "=== SVM ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       0.73      0.79      0.76        14\n",
            "           2       0.57      0.50      0.53         8\n",
            "\n",
            "    accuracy                           0.81        36\n",
            "   macro avg       0.77      0.76      0.76        36\n",
            "weighted avg       0.80      0.81      0.80        36\n",
            "\n",
            "\n",
            "=== SGD Classifier ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87        14\n",
            "           1       0.65      0.93      0.76        14\n",
            "           2       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.72        36\n",
            "   macro avg       0.49      0.62      0.54        36\n",
            "weighted avg       0.57      0.72      0.63        36\n",
            "\n",
            "\n",
            "=== Logistic Regression ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96        14\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.98      0.98        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Accuracy score\n",
        "##와인 데이터는 클래스가 비교적 균형적이므로 정확도를 우선적으로 평가\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# 모델 리스트\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "    \"SGD Classifier\": SGDClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "}\n",
        "\n",
        "# 모델 학습 및 평가\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    model.fit(X_train, y_train)  # 학습\n",
        "    y_pred = model.predict(X_test)  # 예측\n",
        "\n",
        "    # 성능 평가\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkVt1Ho60CHF",
        "outputId": "d93ef07a-1575-4650-ac34-8792a1fd13e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Decision Tree ===\n",
            "Accuracy: 0.94\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        14\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.95      0.93      0.94        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "\n",
            "=== SVM ===\n",
            "Accuracy: 0.81\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       0.73      0.79      0.76        14\n",
            "           2       0.57      0.50      0.53         8\n",
            "\n",
            "    accuracy                           0.81        36\n",
            "   macro avg       0.77      0.76      0.76        36\n",
            "weighted avg       0.80      0.81      0.80        36\n",
            "\n",
            "\n",
            "=== SGD Classifier ===\n",
            "Accuracy: 0.72\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87        14\n",
            "           1       0.65      0.93      0.76        14\n",
            "           2       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.72        36\n",
            "   macro avg       0.49      0.62      0.54        36\n",
            "weighted avg       0.57      0.72      0.63        36\n",
            "\n",
            "\n",
            "=== Logistic Regression ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96        14\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.98      0.98        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. load_breast_cancer : 유방암 진단**"
      ],
      "metadata": {
        "id": "frhGaiq70qxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "mL0Voup40w00"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비\n",
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "lNVlpS9h0zpx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 이해하기\n",
        "import pandas as pd\n",
        "\n",
        "# Feature Data 지정하기\n",
        "X = data.data\n",
        "\n",
        "# Label Data 지정하기\n",
        "y = data.target\n",
        "\n",
        "# Target Names 출력하기\n",
        "print(\"Target Names:\", data.target_names)\n",
        "\n",
        "# 데이터 Describe 해 보기\n",
        "# Feature 데이터를 DataFrame으로 변환하여 기술 통계 출력\n",
        "df = pd.DataFrame(X, columns=data.feature_names)\n",
        "print(\"\\nFeature Data Describe:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMdCbtIG1CKH",
        "outputId": "7b59c5d7-4535-466c-bc1e-1c0b3950015b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: ['malignant' 'benign']\n",
            "\n",
            "Feature Data Describe:\n",
            "       mean radius  mean texture  mean perimeter    mean area  \\\n",
            "count   569.000000    569.000000      569.000000   569.000000   \n",
            "mean     14.127292     19.289649       91.969033   654.889104   \n",
            "std       3.524049      4.301036       24.298981   351.914129   \n",
            "min       6.981000      9.710000       43.790000   143.500000   \n",
            "25%      11.700000     16.170000       75.170000   420.300000   \n",
            "50%      13.370000     18.840000       86.240000   551.100000   \n",
            "75%      15.780000     21.800000      104.100000   782.700000   \n",
            "max      28.110000     39.280000      188.500000  2501.000000   \n",
            "\n",
            "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
            "count       569.000000        569.000000      569.000000           569.000000   \n",
            "mean          0.096360          0.104341        0.088799             0.048919   \n",
            "std           0.014064          0.052813        0.079720             0.038803   \n",
            "min           0.052630          0.019380        0.000000             0.000000   \n",
            "25%           0.086370          0.064920        0.029560             0.020310   \n",
            "50%           0.095870          0.092630        0.061540             0.033500   \n",
            "75%           0.105300          0.130400        0.130700             0.074000   \n",
            "max           0.163400          0.345400        0.426800             0.201200   \n",
            "\n",
            "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
            "count     569.000000              569.000000  ...    569.000000   \n",
            "mean        0.181162                0.062798  ...     16.269190   \n",
            "std         0.027414                0.007060  ...      4.833242   \n",
            "min         0.106000                0.049960  ...      7.930000   \n",
            "25%         0.161900                0.057700  ...     13.010000   \n",
            "50%         0.179200                0.061540  ...     14.970000   \n",
            "75%         0.195700                0.066120  ...     18.790000   \n",
            "max         0.304000                0.097440  ...     36.040000   \n",
            "\n",
            "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
            "count     569.000000       569.000000   569.000000        569.000000   \n",
            "mean       25.677223       107.261213   880.583128          0.132369   \n",
            "std         6.146258        33.602542   569.356993          0.022832   \n",
            "min        12.020000        50.410000   185.200000          0.071170   \n",
            "25%        21.080000        84.110000   515.300000          0.116600   \n",
            "50%        25.410000        97.660000   686.500000          0.131300   \n",
            "75%        29.720000       125.400000  1084.000000          0.146000   \n",
            "max        49.540000       251.200000  4254.000000          0.222600   \n",
            "\n",
            "       worst compactness  worst concavity  worst concave points  \\\n",
            "count         569.000000       569.000000            569.000000   \n",
            "mean            0.254265         0.272188              0.114606   \n",
            "std             0.157336         0.208624              0.065732   \n",
            "min             0.027290         0.000000              0.000000   \n",
            "25%             0.147200         0.114500              0.064930   \n",
            "50%             0.211900         0.226700              0.099930   \n",
            "75%             0.339100         0.382900              0.161400   \n",
            "max             1.058000         1.252000              0.291000   \n",
            "\n",
            "       worst symmetry  worst fractal dimension  \n",
            "count      569.000000               569.000000  \n",
            "mean         0.290076                 0.083946  \n",
            "std          0.061867                 0.018061  \n",
            "min          0.156500                 0.055040  \n",
            "25%          0.250400                 0.071460  \n",
            "50%          0.282200                 0.080040  \n",
            "75%          0.317900                 0.092080  \n",
            "max          0.663800                 0.207500  \n",
            "\n",
            "[8 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 데이터 분리 결과 출력\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXVdgC0p1R8v",
        "outputId": "876091e4-3c24-4f52-bca3-c84b52e42a5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (455, 30)\n",
            "X_test shape: (114, 30)\n",
            "y_train shape: (455,)\n",
            "y_test shape: (114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 모델 리스트\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "    \"SGD Classifier\": SGDClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "}\n",
        "\n",
        "# 각 모델 학습 및 평가\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{model_name} 결과:\")\n",
        "    # 모델 학습\n",
        "    model.fit(X_train, y_train)\n",
        "    # 예측\n",
        "    y_pred = model.predict(X_test)\n",
        "    # 평가\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcPSy4cR1Y-C",
        "outputId": "a34e01e9-5126-426b-9ca3-9b1d58387ab9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        43\n",
            "           1       0.96      0.96      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.94      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "\n",
            "Random Forest 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "\n",
            "SVM 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.93        43\n",
            "           1       0.92      1.00      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "\n",
            "SGD Classifier 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.74      0.85        43\n",
            "           1       0.87      1.00      0.93        71\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.93      0.87      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n",
            "\n",
            "Logistic Regression 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##sklearn.metrics\n",
        "##이진 분류 문제에서 재현율은 양성을 놓치지 않는 데 중요하며, 정밀도는 불필요한 경보를 줄이는 데 중요\n",
        "##F1 Score는 정밀도와 재현율의 균형을 보여주며, ROC-AUC는 모델의 전반적인 성능을 확인할 수 있음\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "\n",
        "# 예측값과 실제값 비교\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{model_name} 결과:\")\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 분류 리포트\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # ROC-AUC (binary classification)\n",
        "    if hasattr(model, \"predict_proba\"):  # 일부 모델은 predict_proba를 지원하지 않음\n",
        "        y_prob = model.predict_proba(X_test)[:, 1]\n",
        "        print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "    elif hasattr(model, \"decision_function\"):\n",
        "        y_score = model.decision_function(X_test)\n",
        "        print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_score):.4f}\")\n",
        "    else:\n",
        "        print(\"\\nROC-AUC Score: 해당 모델은 지원하지 않습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrVj4Net1gc7",
        "outputId": "997b12f0-37e4-422d-fecf-a4cc9c33d810"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree 결과:\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        43\n",
            "           1       0.96      0.96      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.94      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[40  3]\n",
            " [ 3 68]]\n",
            "\n",
            "ROC-AUC Score: 0.9440\n",
            "\n",
            "Random Forest 결과:\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[40  3]\n",
            " [ 1 70]]\n",
            "\n",
            "ROC-AUC Score: 0.9953\n",
            "\n",
            "SVM 결과:\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.93        43\n",
            "           1       0.92      1.00      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[37  6]\n",
            " [ 0 71]]\n",
            "\n",
            "ROC-AUC Score: 0.9934\n",
            "\n",
            "SGD Classifier 결과:\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.74      0.85        43\n",
            "           1       0.87      1.00      0.93        71\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.93      0.87      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[32 11]\n",
            " [ 0 71]]\n",
            "\n",
            "ROC-AUC Score: 0.9761\n",
            "\n",
            "Logistic Regression 결과:\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[39  4]\n",
            " [ 1 70]]\n",
            "\n",
            "ROC-AUC Score: 0.9977\n"
          ]
        }
      ]
    }
  ]
}